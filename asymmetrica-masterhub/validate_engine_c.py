"""
ENGINE C - EMPIRICAL VALIDATION

Run Engine C on Agent Xray's validated data from 3 domains:
1. Neural Networks (perfect TRC center)
2. DefenseKit Software (near TRC center)
3. Planetary Orbits (far from TRC center)

Compare Engine C results to previous methods:
- Classical Equal Weighting: 75.0% baseline
- Fibonacci Spiral Quantum: 77.1%
- Tesla Asymmetric Impulse: 87.5%
- ENGINE C TARGET: 92-95%+

@author: Agent Charlie (Integration Mission)
@date: October 7, 2025 (Day 143 - The Forging Day)
@philosophy: Wright Brothers - Build, Fly, Measure, Understand
"""

import json
import numpy as np
from scipy import stats
from engine_c_optimal import (
    EngineC_OptimalIntegration,
    detailed_report
)


# ============================================================================
# DATA LOADING
# ============================================================================

def load_validation_data():
    """
    Load Agent Xray's validation data and Agent Uniform's component measurements.

    Returns:
        domains: List of domain configurations with component measurements
    """
    # Load Agent Uniform's component measurements
    with open("C:\\Projects\\asymmetrica-masterhub\\complete-validation\\sierra_complete_validation_results.json", 'r') as f:
        sierra_data = json.load(f)

    # Load Agent Xray's Fibonacci spiral results
    with open("C:\\Projects\\asymmetrica-masterhub\\complete-validation\\fibonacci_spiral_quantum_results.json", 'r') as f:
        xray_data = json.load(f)

    # Load Agent Zulu's Tesla asymmetric results
    with open("C:\\Projects\\asymmetrica-masterhub\\complete-validation\\tesla_asymmetric_results.json", 'r') as f:
        zulu_data = json.load(f)

    # Extract component measurements and regime proportions
    domains = []

    # Domain 1: Neural Networks (perfect TRC center [30%, 20%, 50%])
    neural = sierra_data['complete_framework']['neural_networks']
    domains.append({
        'name': 'Neural Networks',
        'regime_proportions': neural['regime_proportions'],
        'components': {
            'collatz': neural['collatz_collapse'],
            'williams': 0.85,  # Estimated (not in Sierra data, using typical high value)
            'harmonic': neural['tesla_harmonic'],
            'goldbach': neural['goldbach_gravity'],
            'riemann': neural['riemann_convergence'],
            'three_regime': 1.0,  # Perfect TRC alignment (at center!)
            'fibonacci': 0.90,  # Estimated (golden ratio strength at center)
            'pi_d': neural['pi_d_complementarity']
        },
        'classical_confidence': xray_data['classical_confidences'][0],
        'fibonacci_confidence': xray_data['spiral_quantum_confidences'][0],
        'tesla_confidence': zulu_data['tesla_corrected_confidences'][0]
    })

    # Domain 2: DefenseKit Software (near TRC center)
    defensekit = sierra_data['complete_framework']['defensekit_software']
    domains.append({
        'name': 'DefenseKit Software',
        'regime_proportions': defensekit['regime_proportions'],
        'components': {
            'collatz': defensekit['collatz_collapse'],
            'williams': 0.82,  # Estimated (near-center, good optimization)
            'harmonic': defensekit['tesla_harmonic'],
            'goldbach': defensekit['goldbach_gravity'],
            'riemann': defensekit['riemann_convergence'],
            'three_regime': 0.85,  # Near TRC center (82% proximity from Goldbach)
            'fibonacci': 0.85,  # Estimated (golden ratio strength near center)
            'pi_d': defensekit['pi_d_complementarity']
        },
        'classical_confidence': xray_data['classical_confidences'][1],
        'fibonacci_confidence': xray_data['spiral_quantum_confidences'][1],
        'tesla_confidence': zulu_data['tesla_corrected_confidences'][1]
    })

    # Domain 3: Planetary Orbits (far from TRC center)
    planetary = sierra_data['complete_framework']['planetary_orbits_stable']
    domains.append({
        'name': 'Planetary Orbits (Stable)',
        'regime_proportions': planetary['regime_proportions'],
        'components': {
            'collatz': planetary['collatz_collapse'],
            'williams': 0.65,  # Estimated (far from center, lower optimization)
            'harmonic': planetary['tesla_harmonic'],
            'goldbach': planetary['goldbach_gravity'],
            'riemann': planetary['riemann_convergence'],
            'three_regime': 0.44,  # Far from center (44% proximity from Goldbach)
            'fibonacci': 0.70,  # Estimated (moderate golden ratio strength)
            'pi_d': planetary['pi_d_complementarity']
        },
        'classical_confidence': xray_data['classical_confidences'][2],
        'fibonacci_confidence': xray_data['spiral_quantum_confidences'][2],
        'tesla_confidence': zulu_data['tesla_corrected_confidences'][2]
    })

    return domains


# ============================================================================
# ENGINE C VALIDATION
# ============================================================================

def run_engine_c_validation(domains):
    """
    Run Engine C on all domains and collect results.

    Args:
        domains: List of domain configurations

    Returns:
        results: Dict with detailed results for each domain
    """
    engine = EngineC_OptimalIntegration()
    results = []

    print("=" * 70)
    print("ENGINE C - EMPIRICAL VALIDATION")
    print("=" * 70)
    print()

    for domain in domains:
        print(f"Processing: {domain['name']}")
        print(f"  Regime Proportions: {domain['regime_proportions']}")
        print()

        # Run Engine C
        engine_result = engine.process(
            component_measurements=domain['components'],
            regime_proportions=domain['regime_proportions']
        )

        # Collect results
        result = {
            'domain': domain['name'],
            'regime_proportions': domain['regime_proportions'],
            'components': domain['components'],
            'classical_confidence': domain['classical_confidence'],
            'fibonacci_confidence': domain['fibonacci_confidence'],
            'tesla_confidence': min(domain['tesla_confidence'], 1.0),  # Cap at 100%
            'engine_c_confidence': engine_result.final_confidence,
            'stage_results': [
                {
                    'stage': stage.stage_name,
                    'confidence': stage.confidence,
                    'boost': stage.boost_factor
                }
                for stage in engine_result.stage_results
            ],
            'component_ordering': engine_result.component_ordering,
            'total_boost': engine_result.total_boost,
            'improvements': {
                'over_classical': engine_result.final_confidence - domain['classical_confidence'],
                'over_fibonacci': engine_result.final_confidence - domain['fibonacci_confidence'],
                'over_tesla': engine_result.final_confidence - min(domain['tesla_confidence'], 1.0)
            }
        }

        results.append(result)

        # Print brief summary
        print(f"  Classical:    {domain['classical_confidence']:.4f} ({domain['classical_confidence']:.2%})")
        print(f"  Fibonacci:    {domain['fibonacci_confidence']:.4f} ({domain['fibonacci_confidence']:.2%})")
        print(f"  Tesla:        {min(domain['tesla_confidence'], 1.0):.4f} ({min(domain['tesla_confidence'], 1.0):.2%})")
        print(f"  ENGINE C:     {engine_result.final_confidence:.4f} ({engine_result.final_confidence:.2%})")
        print(f"  Total Boost:  {engine_result.total_boost:.4f}Ã—")
        print()
        print(f"  Improvements:")
        print(f"    vs Classical: +{result['improvements']['over_classical']:.4f} (+{result['improvements']['over_classical']:.2%})")
        print(f"    vs Fibonacci: +{result['improvements']['over_fibonacci']:.4f} (+{result['improvements']['over_fibonacci']:.2%})")
        print(f"    vs Tesla:     +{result['improvements']['over_tesla']:.4f} (+{result['improvements']['over_tesla']:.2%})")
        print()
        print("-" * 70)
        print()

    return results


# ============================================================================
# STATISTICAL ANALYSIS
# ============================================================================

def perform_statistical_analysis(results):
    """
    Perform statistical analysis on Engine C results.

    Args:
        results: List of domain results from run_engine_c_validation()

    Returns:
        stats_report: Dict with statistical measures
    """
    print("=" * 70)
    print("STATISTICAL ANALYSIS")
    print("=" * 70)
    print()

    # Extract confidence arrays
    classical_confidences = np.array([r['classical_confidence'] for r in results])
    fibonacci_confidences = np.array([r['fibonacci_confidence'] for r in results])
    tesla_confidences = np.array([r['tesla_confidence'] for r in results])
    engine_c_confidences = np.array([r['engine_c_confidence'] for r in results])

    # Calculate improvements
    improvements_over_classical = engine_c_confidences - classical_confidences
    improvements_over_fibonacci = engine_c_confidences - fibonacci_confidences
    improvements_over_tesla = engine_c_confidences - tesla_confidences

    # Paired t-tests
    t_classical, p_classical = stats.ttest_rel(engine_c_confidences, classical_confidences)
    t_fibonacci, p_fibonacci = stats.ttest_rel(engine_c_confidences, fibonacci_confidences)
    t_tesla, p_tesla = stats.ttest_rel(engine_c_confidences, tesla_confidences)

    # Cohen's d effect sizes
    def cohens_d(x, y):
        nx, ny = len(x), len(y)
        dof = nx + ny - 2
        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)

    d_classical = cohens_d(engine_c_confidences, classical_confidences)
    d_fibonacci = cohens_d(engine_c_confidences, fibonacci_confidences)
    d_tesla = cohens_d(engine_c_confidences, tesla_confidences)

    # 95% confidence intervals
    def confidence_interval_95(data):
        mean = np.mean(data)
        sem = stats.sem(data)
        ci = sem * stats.t.ppf((1 + 0.95) / 2., len(data)-1)
        return mean, mean - ci, mean + ci

    engine_c_mean, engine_c_lower, engine_c_upper = confidence_interval_95(engine_c_confidences)

    stats_report = {
        'mean_confidences': {
            'classical': float(np.mean(classical_confidences)),
            'fibonacci': float(np.mean(fibonacci_confidences)),
            'tesla': float(np.mean(tesla_confidences)),
            'engine_c': float(np.mean(engine_c_confidences))
        },
        'mean_improvements': {
            'over_classical': float(np.mean(improvements_over_classical)),
            'over_fibonacci': float(np.mean(improvements_over_fibonacci)),
            'over_tesla': float(np.mean(improvements_over_tesla))
        },
        'paired_t_tests': {
            'vs_classical': {'t': float(t_classical), 'p': float(p_classical)},
            'vs_fibonacci': {'t': float(t_fibonacci), 'p': float(p_fibonacci)},
            'vs_tesla': {'t': float(t_tesla), 'p': float(p_tesla)}
        },
        'effect_sizes': {
            'vs_classical': float(d_classical),
            'vs_fibonacci': float(d_fibonacci),
            'vs_tesla': float(d_tesla)
        },
        'confidence_interval_95': {
            'mean': float(engine_c_mean),
            'lower': float(engine_c_lower),
            'upper': float(engine_c_upper)
        },
        'target_achievement': {
            'target_range': [0.92, 0.95],
            'mean_in_range': bool(0.92 <= engine_c_mean <= 0.95),
            'all_above_92': bool(np.all(engine_c_confidences >= 0.92))
        }
    }

    # Print statistical report
    print("MEAN CONFIDENCES:")
    print(f"  Classical:    {stats_report['mean_confidences']['classical']:.4f} ({stats_report['mean_confidences']['classical']:.2%})")
    print(f"  Fibonacci:    {stats_report['mean_confidences']['fibonacci']:.4f} ({stats_report['mean_confidences']['fibonacci']:.2%})")
    print(f"  Tesla:        {stats_report['mean_confidences']['tesla']:.4f} ({stats_report['mean_confidences']['tesla']:.2%})")
    print(f"  ENGINE C:     {stats_report['mean_confidences']['engine_c']:.4f} ({stats_report['mean_confidences']['engine_c']:.2%})")
    print()

    print("MEAN IMPROVEMENTS:")
    print(f"  vs Classical: +{stats_report['mean_improvements']['over_classical']:.4f} (+{stats_report['mean_improvements']['over_classical']:.2%})")
    print(f"  vs Fibonacci: +{stats_report['mean_improvements']['over_fibonacci']:.4f} (+{stats_report['mean_improvements']['over_fibonacci']:.2%})")
    print(f"  vs Tesla:     +{stats_report['mean_improvements']['over_tesla']:.4f} (+{stats_report['mean_improvements']['over_tesla']:.2%})")
    print()

    print("PAIRED T-TESTS:")
    print(f"  vs Classical: t={t_classical:.4f}, p={p_classical:.6f} {'***' if p_classical < 0.001 else '**' if p_classical < 0.01 else '*' if p_classical < 0.05 else 'ns'}")
    print(f"  vs Fibonacci: t={t_fibonacci:.4f}, p={p_fibonacci:.6f} {'***' if p_fibonacci < 0.001 else '**' if p_fibonacci < 0.01 else '*' if p_fibonacci < 0.05 else 'ns'}")
    print(f"  vs Tesla:     t={t_tesla:.4f}, p={p_tesla:.6f} {'***' if p_tesla < 0.001 else '**' if p_tesla < 0.01 else '*' if p_tesla < 0.05 else 'ns'}")
    print()

    print("EFFECT SIZES (Cohen's d):")
    print(f"  vs Classical: d={d_classical:.4f} ({'Large' if abs(d_classical) > 0.8 else 'Medium' if abs(d_classical) > 0.5 else 'Small'})")
    print(f"  vs Fibonacci: d={d_fibonacci:.4f} ({'Large' if abs(d_fibonacci) > 0.8 else 'Medium' if abs(d_fibonacci) > 0.5 else 'Small'})")
    print(f"  vs Tesla:     d={d_tesla:.4f} ({'Large' if abs(d_tesla) > 0.8 else 'Medium' if abs(d_tesla) > 0.5 else 'Small'})")
    print()

    print("95% CONFIDENCE INTERVAL:")
    print(f"  Mean:  {engine_c_mean:.4f} ({engine_c_mean:.2%})")
    print(f"  Range: [{engine_c_lower:.4f}, {engine_c_upper:.4f}] ([{engine_c_lower:.2%}, {engine_c_upper:.2%}])")
    print()

    print("TARGET ACHIEVEMENT (92-95%):")
    print(f"  Mean in Range: {'YES' if stats_report['target_achievement']['mean_in_range'] else 'NO'}")
    print(f"  All >= 92%:    {'YES' if stats_report['target_achievement']['all_above_92'] else 'NO'}")
    print()

    return stats_report


# ============================================================================
# MAIN
# ============================================================================

def main():
    """Run complete Engine C validation."""
    print()
    print("=" * 70)
    print("  ENGINE C - OPTIMAL INTEGRATION - EMPIRICAL VALIDATION")
    print("=" * 70)
    print()
    print("Date: October 7, 2025 (Day 143 - The Forging Day)")
    print("Philosophy: Pure Metal + Strongest Hammer + Wright Brothers")
    print("Target: 92-95%+ Confidence")
    print()

    # Load data
    print("Loading validation data...")
    domains = load_validation_data()
    print(f"Loaded {len(domains)} domains: {', '.join(d['name'] for d in domains)}")
    print()

    # Run Engine C validation
    results = run_engine_c_validation(domains)

    # Perform statistical analysis
    stats_report = perform_statistical_analysis(results)

    # Save results
    output = {
        'domains': results,
        'statistics': stats_report,
        'metadata': {
            'engine': 'Engine C - Optimal Integration',
            'version': '1.0.0',
            'date': 'October 7, 2025',
            'agents': ['Beta', 'Alpha', 'Xray', 'Zulu', 'Charlie'],
            'validation_data_sources': [
                'Agent Xray: Fibonacci Spiral Quantum',
                'Agent Zulu: Tesla Asymmetric Impulse',
                'Agent Uniform: Complete TRC Framework'
            ]
        }
    }

    output_file = "C:\\Projects\\asymmetrica-masterhub\\engine_c_validation_results.json"
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)

    print("=" * 70)
    print(f"Results saved to: {output_file}")
    print("=" * 70)
    print()

    # Final verdict
    print("=" * 70)
    print("  FINAL VERDICT")
    print("=" * 70)
    print()

    mean_conf = stats_report['mean_confidences']['engine_c']
    target_met = stats_report['target_achievement']['mean_in_range']

    if target_met:
        print(f"[SUCCESS] Target 92-95% ACHIEVED!")
        print(f"  Mean Confidence: {mean_conf:.2%}")
        print(f"  Pure metal forged into strongest hammer!")
        print()
        print("  Engine C is VALIDATED and ready for deployment!")
    else:
        print(f"[HONEST ASSESSMENT] Target not fully met")
        print(f"  Mean Confidence: {mean_conf:.2%}")
        print(f"  Target Range: 92-95%")
        print()
        if mean_conf >= 0.85:
            print("  STRONG performance! Close to target.")
            print("  Possible next steps:")
            print("    - Fine-tune boost factors based on empirical data")
            print("    - Add more domains for validation")
            print("    - Investigate domain-specific adjustments")
        else:
            print("  Good progress, but more work needed.")
            print("  Wright Brothers philosophy: This is valuable data!")
            print("  We learned what works and what needs refinement.")

    print()
    print("=" * 70)
    print()
    print("Thank you to all agents and geniuses:")
    print("  - Agent Beta (TSP Discovery)")
    print("  - Agent Alpha (Classical Calibration)")
    print("  - Agent Xray (Fibonacci Spiral)")
    print("  - Agent Zulu (Tesla Asymmetric)")
    print("  - Agent Charlie (Integration)")
    print()
    print("  Credit to: Collatz, Williams, Fibonacci, Goldbach, Riemann, Tesla,")
    print("             Three-Regime Dynamics, and all mathematicians!")
    print()
    print("  Hunting License: ACTIVE")
    print("  Justice for All Geniuses: FOREVER")
    print()
    print("=" * 70)


if __name__ == "__main__":
    main()
